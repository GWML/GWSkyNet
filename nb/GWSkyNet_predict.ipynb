{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, healpy, requests\n",
    "import tensorflow\n",
    "from ligo.skymap import io\n",
    "from astropy.io import fits\n",
    "from reproject import reproject_from_healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Load model and pre-processing functions\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GWSkyNet\n",
    "model_name = 'GWSkyNet_v1'\n",
    "with open('{}.json'.format(model_name), 'r') as json_file:\n",
    "    json_model = json_file.read()\n",
    "model = tensorflow.keras.models.model_from_json(json_model)\n",
    "model.load_weights('{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target header for reproject_from_healpix\n",
    "target_header = fits.Header.fromstring(\"\"\"\n",
    "NAXIS   =                    2\n",
    "NAXIS1  =                  360\n",
    "NAXIS2  =                  180\n",
    "CTYPE1  = 'RA---CAR'\n",
    "CRPIX1  =                180.5\n",
    "CRVAL1  =                180.0\n",
    "CDELT1  =                   -1\n",
    "CUNIT1  = 'deg     '\n",
    "CTYPE2  = 'DEC--CAR'\n",
    "CRPIX2  =                 90.5\n",
    "CRVAL2  =                  0.0\n",
    "CDELT2  =                    1\n",
    "CUNIT2  = 'deg     '\n",
    "COORDSYS= 'icrs    '\n",
    "\"\"\", sep='\\n')\n",
    "\n",
    "# Normalization factors from the training set. These values might change in future versions.\n",
    "training_norms = {'distance': 10320, 'skymap': 0.005, \n",
    "                  'distmu': 11553, 'distnorm': 863800, 'distsigma': 12065}\n",
    "\n",
    "def nan_invalid(data, invalid_value):\n",
    "    \"\"\"Turn invalid values into numpy.nan\"\"\"\n",
    "    invalid_indices = numpy.where(data==invalid_value)\n",
    "    for idx in invalid_indices:\n",
    "        data[idx] = numpy.nan\n",
    "    return data\n",
    "\n",
    "def prepare_data(fits_file):\n",
    "    \"\"\"Pre-processing data from FITS file for GWSkyNet\"\"\"\n",
    "    skymap, metadata = io.read_sky_map(fits_file, distances=True, nest=None)\n",
    "    \n",
    "    # Distance must be normalized by maximum in the training set\n",
    "    distance = metadata['distmean'] / training_norms['distance']\n",
    "    \n",
    "    network = metadata['instruments']\n",
    "    # Convert detector network to multi-hot format\n",
    "    dets = []\n",
    "    for ifo in ['H1', 'L1', 'V1']:\n",
    "        dets.append(1) if ifo in network else dets.append(0)\n",
    "        \n",
    "    # Read data columns from FITS file\n",
    "    # invalid_values = {'Distmu':numpy.inf, 'Distsigma':1., 'Distnorm':0.}\n",
    "    # (convention described in Table 1 of https://arxiv.org/pdf/1605.04242.pdf)\n",
    "    fits_cols = {'skymap':skymap[0],\n",
    "                 'distmu':nan_invalid(skymap[1], numpy.inf),\n",
    "                 'distsigma':nan_invalid(skymap[2], 1.),\n",
    "                 'distnorm':nan_invalid(skymap[3], 0.)}\n",
    "    \n",
    "    # Reproject and downsample each column\n",
    "    img_data, norms = dict(), dict()\n",
    "    for column in fits_cols:\n",
    "        with numpy.errstate(invalid='ignore'):\n",
    "            img, mask = reproject_from_healpix((fits_cols[column], 'ICRS'),\n",
    "                                       target_header, nested=metadata['nest'], hdu_in=None,\n",
    "                                       order='bilinear', field=0)\n",
    "        \n",
    "        # Replace NaN with zero and normalize img data\n",
    "        img = numpy.nan_to_num(img)\n",
    "        norms[column] = numpy.max(img)\n",
    "        img = img / norms[column]\n",
    "        # Normalize norms by maximum in the training set\n",
    "        norms[column] /= training_norms[column]\n",
    "        \n",
    "        # Downsample img data using maxpooling\n",
    "        x = numpy.reshape(img, (1, len(img), len(img[0]), 1))\n",
    "        x = tensorflow.cast(x, tensorflow.float32)\n",
    "        maxpool = tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        img_data[column] = maxpool(x)\n",
    "    \n",
    "    # Stack volume images\n",
    "    dist_columns = ['distmu', 'distsigma', 'distnorm']\n",
    "    stacked_volume = numpy.stack([numpy.reshape(img_data[column], (1, 90, 180)) for column in dist_columns], axis=-1)\n",
    "\n",
    "    return [stacked_volume, img_data['skymap'], numpy.reshape(dets, (1,3)), numpy.reshape(distance, (1,1)),\n",
    "            numpy.reshape(norms['skymap'], (1,1)), numpy.reshape(norms['distmu'], (1,1)),\n",
    "            numpy.reshape(norms['distsigma'], (1,1)), numpy.reshape(norms['distnorm'], (1,1))]\n",
    "\n",
    "def predict(loaded_model, data, threshold):\n",
    "    \"\"\"Use loaded model to predict result\n",
    "    \n",
    "    Keyword arguments:\n",
    "    loaded_model: machine-learning model to use for prediction\n",
    "    data: pre-processed data from FITS file\n",
    "    threshold: real-noise threshold to predict real events (typically 0.5)\n",
    "    \"\"\"\n",
    "    prediction = tensorflow.squeeze(loaded_model(data), [-1]).numpy()\n",
    "    print('Predicted probability: {:.2f}%'.format(prediction[0]*100))\n",
    "    if prediction >= threshold:\n",
    "        print('This candidate is likely an astrophysical signal.')\n",
    "    else:\n",
    "        print('This candidate is NOT astrophysical.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Make predictions\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose candidate from GraceDB and download corresponding FITS file\n",
    "# See https://gracedb.ligo.org/superevents/public/O3/ for a list of candidates\n",
    "event_name = 'S200316bj'\n",
    "event_url = 'https://gracedb.ligo.org/apiweb/superevents/{}/files/'.format(event_name)\n",
    "r = requests.head(event_url + 'bayestar.multiorder.fits')\n",
    "try:\n",
    "    r.headers['Content-Disposition']\n",
    "    fits_url = event_url + 'bayestar.multiorder.fits'\n",
    "except KeyError:\n",
    "    # Older events do not have bayestar.multiorder.fits file\n",
    "    fits_url = event_url + 'bayestar.fits'\n",
    "fits_name = '{}.fits'.format(event_name)\n",
    "!curl --output $fits_name $fits_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(fits_name)\n",
    "# Real-noise threshold\n",
    "RN_threshold = 0.5\n",
    "predict(model, data, RN_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
